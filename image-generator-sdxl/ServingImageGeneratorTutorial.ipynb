{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving a Lightweight Text-to-Image Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating images from text is a popular use-case for artificial intelligence. In this tutorial, we create a function service that runs an especially quick variant of a [Stable Diffusion](https://en.wikipedia.org/wiki/Stable_Diffusion), namely `\"sdxl-turbo\"` by [Stability AI](https://stability.ai/).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure you've installed the [Covalent Cloud SDK](https://pypi.org/project/covalent-cloud/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# pip install -U covalent-cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Once that's done, import `covalent_cloud` and a couple other dependencies (these are built-in)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "import covalent_cloud as cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your Covalent Cloud API key if you haven't already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.save_api_key(\"xxxxxxxxxxx-1jcwdLXqMlUA8F7pz0QTrCNWXENyLrOpDZwJc2EdMfTth0neM3dguXQMPlSyVQ675r92-5-8_p-Q\")\n",
    "cc.settings.dispatcher_uri = \"https://api.covalent.xyz\"  # target integration env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cloud Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The service that we define in this tutorial will use the following [environment](https://docs.covalent.xyz/docs/cloud/guides/cloud_custom_environments).\n",
    "\n",
    "Environment creation can take a few minutes, but luckily we only need to do it once! After that, the environment can be referenced by name (i.e. `\"text-to-image-turbo\"`).\n",
    "\n",
    "Once the environment is ready to go, we'll refer to it inside our executor in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc.create_env(\n",
    "    name=\"text-to-image-turbo-new\",\n",
    "    pip=[\"accelerate\", \"diffusers\", \"transformers\"],\n",
    "    conda=[\"python=3.8\"],\n",
    "    wait=True,  # remove this to create asynchronously\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Set of Compute Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of any executor in Covalent is to specify a set of modular compute resources. See [here](https://docs.covalent.xyz/docs/cloud/guides/cloud_defining_resources) for more information on available compute resources.\n",
    "\n",
    "This particular executor specifies 25 CPUs, 56 GB of RAM, and a single NVIDIA L40 GPU. We'll assign it to our service in the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_executor = cc.CloudExecutor(\n",
    "    env=\"text-to-image-turbo\",\n",
    "    num_cpus=25,\n",
    "    memory=\"56 GB\",\n",
    "    num_gpus=1,\n",
    "    gpu_type=\"v100\",\n",
    "    time_limit=181800,  # maximum lifetime of the service\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving The Image Generator Model\n",
    "\n",
    "Every function service in Covalent Cloud contains one initializer function and zero or more API endpoints.\n",
    "\n",
    "We start by defining the initializer. This function will prep the service for real-time inference by pre-loading the model into vRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@cc.service(executor=gpu_executor, name=\"SDXL-Turbo Service\")\n",
    "def text_to_image_service(model=\"stabilityai/sdxl-turbo\"):\n",
    "\n",
    "    \"\"\"Creates an SDXL Image Generator service\"\"\"\n",
    "\n",
    "    # Importing here avoids local dependencies.\n",
    "    from torch import float16\n",
    "    from diffusers import AutoPipelineForText2Image\n",
    "\n",
    "    pipeline = AutoPipelineForText2Image.from_pretrained(\n",
    "        model, torch_dtype=float16, variant=\"fp16\"\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    return {\"pipeline\": pipeline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's add an API endpoint. This endpoint will generate an image from the contents of the `text` argument. It will then serialize the image and return it as a base64-encoded string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@text_to_image_service.endpoint(route=\"/text-to-image\")\n",
    "def generate_image(pipeline, text, num_inference_steps=1):\n",
    "\n",
    "    \"\"\"Generate an image from user-specified text.\"\"\"\n",
    "\n",
    "    # This is the `pipeline` returned by the initializer\n",
    "    image = pipeline(prompt=text, num_inference_steps=num_inference_steps, guidance_scale=0.0).images[0]\n",
    "\n",
    "    # Serialize\n",
    "    bytes_io = io.BytesIO()\n",
    "    image.save(bytes_io, format='PNG')\n",
    "    image_as_str = base64.b64encode(bytes_io.getvalue()).decode('utf-8')\n",
    "\n",
    "    return image_as_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy The Service\n",
    "\n",
    "This code block will deploy the service (asynchronously), wait for it to become active, then print some useful information.\n",
    "\n",
    "Run the code block to do all of the above. Deployment usually takes 5-15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator = cc.deploy(text_to_image_service)()\n",
    "\n",
    "# Wait for active state and reload the client.\n",
    "image_generator = cc.get_deployment(image_generator.function_id, wait=True)\n",
    "\n",
    "# Print information about the deployment.\n",
    "print(image_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Images\n",
    "\n",
    "Now that the service is deployed and active, we can start generating images by sending requests to the `/text-to-image` endpoint. You can image building a front-end that consumes this API to generate images from user-provided text. In fact, this model is fast enough to do that almost real-time (generating a new image every 3 seconds or so).\n",
    "\n",
    "For the purposes of this tutorial, we'll generate a single image using the code below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a brief utility function to help us visualize the images. Make sure you have `pillow` installed for this to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pip install -U pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def deserialize_image(ser_img):\n",
    "    image_arr = io.BytesIO(base64.b64decode(ser_img))\n",
    "    return Image.open(image_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell in a Jupyter Notebook and the image will be displayed inline.\n",
    "\n",
    "Notice that our Python client automatically includes methods corresponding to each endpoint (with \"-\" replaced by \"_\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Elon musk\"\n",
    "\n",
    "# Use the endpoint to generate an image.\n",
    "serialized_image = image_generator.text_to_image(text=text)\n",
    "deserialize_image(serialized_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Danger Zone!\n",
    "\n",
    "Run cell below to tear down the deployment and release all its resources. (You can also do this from the Covalent Cloud UI.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import covalent_cloud as cc\n",
    "# image_generator = cc.get_deployment(\"6650d922f7d37dbf2a468bab\")\n",
    "# image_generator.teardown()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
